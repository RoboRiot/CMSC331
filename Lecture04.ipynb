{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Job of Lexical Analysis\n",
    "- Read in characters from a file\n",
    "- Determine the groupings of characters (the lexemes)\n",
    "    - The lowest level(s) of the grammar\n",
    "- Assign the lexemes to a token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where Lexical Analysis Fits in\n",
    "<img alt=\"Where in the process we are\" src=\"lexprocess.svg\" style=\"width: 75%; height: auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another View of Lexical Analysis\n",
    "![Syntax highlighted in the atom.io text editor](https://i.github-camo.com/a4cd12f0aa9610f5487f031d3163918abdcb42ec/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f3637313337382f323236353637312f64303265626565382d396538352d313165332d396238632d3132623263623730313565332e706e67)\n",
    "From https://atom.io/themes/monokai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methods of Lexical Anaylsis\n",
    "Lexical Anaylsis boils down to matching patterns.  \n",
    "There are several ways to do this\n",
    "- Use formal descriptions and regular expressions to describe the patterns\n",
    "- Use a state transition diagram and accompying implementation\n",
    "- Use a state transition diagram and manually construct a table-driven implentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regular Expressions\n",
    "\n",
    "- A notation that is used to describe patterns\n",
    "- Is simpler and less expresive than BNF\n",
    "- Consists of three basic operations:\n",
    " - Concatenation **( ab )** \n",
    " - Union  **a | b**\n",
    " - Kleene Star or Kleene Closure __a*__ = __$\\epsilon$|a|aa|aaa|....__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regular Expression Notataion\n",
    "- Has some syntactic sugar that could be constructed from the above\n",
    " - Parentheses __( a ( b | c ) )__ == **ab|ac**\n",
    " - Kleene Plus __a+__ == __aa\\*__\n",
    " - Zero or One Operator __a?__ = __a | $\\epsilon$__ \n",
    " - Character classes  __[a-z]__ == __a | b | c | ... | y | z__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Can use identifiers to break up long patterns\n",
    " - ONES = (one|two|three| ... | ten)\n",
    " - TEENS = (eleven|twelve|thirteen|...|nineteen)\n",
    " - TENS = (twenty|thirty|forty|...|ninety)\n",
    " - MONEY = ((ONES|TEENS)| TENS ONES)(CENTS | (DOLLARS ((ONES|TEENS)| TENS ONES) CENTS)\n",
    "- Can be simplified even further\n",
    " - X = (ONES | TEENS)\n",
    " - Y = TENS ONES\n",
    " - NUMBER = (X | Y)\n",
    " - MONEY2 = NUMBER (CENTS | DOLLARS NUMBER CENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RegEx Examples\n",
    "\n",
    "Over the alphabet {a,b} give a regular expression for\n",
    "\n",
    "- Strings with an even number of a's\n",
    "- Strings with a length that is a multiple of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regex in the Real Word\n",
    "* Most programming languages support far more complex regular expressions\n",
    "* Python uses a style of regex known as perl compatable regular expressiosn (PCRE)\n",
    "    * \\d stands for all digits\n",
    "    * \\w for all alphanumeric characters\n",
    "* Can also be used in `grep` by using the -P flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Real World Uses of Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 bryan bryan 2.0G Jan 27  2017 /home/bryan/wackypediaFlat.slim\n"
     ]
    }
   ],
   "source": [
    "ls -lh ~/wackypediaFlat.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800-801-9322\n",
      "888-241-4556\n",
      "800-818-8589\n",
      "465-577-4922\n",
      "465-577-4923\n",
      "465-823-7231\n",
      "800-567-5111\n",
      "510-234-9054\n",
      "907-248-3780\n",
      "866-445-6580\n",
      "grep: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "grep -oP \"\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d\" ~/wackypediaFlat.slim | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Slovenia is Ljubljana\n",
      "The capital of Berry is Bourges\n",
      "The capital of Chile is Santiago\n",
      "The capital of Alabama is Montgomery\n",
      "The capital of Anambra is Awka\n",
      "The capital of Cybertron is Iacon\n",
      "The capital of Ghor is Chaghcharan\n",
      "The capital of Colombia is Bogota\n",
      "The capital of Boharo is Dhahar\n",
      "The capital of Cundinamarca is Bogota\n"
     ]
    }
   ],
   "source": [
    "grep -oP \"[tT]he capital of [A-Z]\\w+ is [A-Z]\\w+\" ~/wackypediaFlat.slim | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finite Automata\n",
    "- A class of mathematical machines\n",
    "- Represented by a state transition diagram\n",
    "- Recognizes strings that can be described by regular expressions\n",
    "\n",
    "![Finite Automata to recognize money](moneyDFA.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deterministic Finite Automata\n",
    "\n",
    "Finite automata that obey certain rules\n",
    "\n",
    "- For each state, any given input only provides on possible trasition\n",
    "- You cannot transition between two states with out looking at the input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DFA Practice\n",
    "\n",
    "Over the alphabet {a,b} give a DFA that accepts:\n",
    "\n",
    "- Strings with no more than 3 a's\n",
    "- Strings with a length that is a multiple of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-Deterministic Finite State Automaton (NFA)\n",
    "* NFAs are computationally equivalent to DFAs\n",
    "* NFAs allow:\n",
    "    * A transition over the empty string $\\epsilon$\n",
    "    * Multiple transitions given the same input and same state\n",
    " \n",
    "![Example of two transitions](NFA1.jpg)\n",
    "                                                                                                                                                  \n",
    "![Example of empty transition](NFA2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing a DFA with a table\n",
    "- If we number (or otherwise label) each state, we can create a table where\n",
    "    - the rows are the states\n",
    "    - the columns are the inputs\n",
    "    - the cell value is which state to go to next\n",
    "- Process input one character at a time, updating a variable that holds the current state\n",
    "- After processing input, if we are in an accept state, accept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"aa.png\" style=\"height:30vh;margin:0px auto;\" alt=\"Three state DFA, transition from state 1 to state 2 on an 'a', from state 2 to state 1 on a 'b' and from state 2 to state 3 on an 'a'\">\n",
    "<table style=\"font-size:1.5em;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th></th><th>a</th><th>b</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"border-right:1px solid black;\">1</td>\n",
    "<td>2</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border-right:1px solid black;\">2</td>\n",
    "<td>3</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border-right:1px solid black;\">3</td>\n",
    "<td>3</td>\n",
    "<td>3</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lex\n",
    "\n",
    "- Lexical analyzer generator\n",
    " - It writes a lexical analyzer\n",
    "- Assumption\n",
    " - each token matches a regular expression\n",
    "- Needs\n",
    " - set of regular expressions\n",
    " - for each expression an action\n",
    "- Produces\n",
    " - A C program\n",
    "- Automatically handles many tricky problems\n",
    "- flex is the GNU version of the venerable unix tool lex.\n",
    " - Produces highly optimized code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lex File Layout\n",
    "- A lex file consist of three sections, separated by a line containing only `%%`\n",
    "    - Definitions\n",
    "    - Rules\n",
    "    - Subroutines\n",
    "```lex\n",
    "DEFINITIONS\n",
    "%%\n",
    "RULES\n",
    "%%\n",
    "SUBROUTINES\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lex Pipeline\n",
    "* Lex files are traditional named with an `.l` suffix\n",
    "* First the lex files is processed by `lex` or `flex` which generates C code\n",
    "```bash\n",
    "flex -ooutput.c input.l\n",
    "```\n",
    "* Next the c file is compiled. You **must** use the `-lfl` flag\n",
    "```bash\n",
    "gcc -oexample_lex example_lex.c -lfl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lex Example\n",
    "```c\n",
    "/* scanner for a toy Pascal-like language */\n",
    "%{\n",
    "#include <math.h> /* needed for call to atof() */\n",
    "%}\n",
    "DIG [0-9]\n",
    "ID [a-z][a-z0-9]*\n",
    "%%\n",
    "{DIG}+ printf(\"Integer: %s (%d)\\n\", yytext, atoi(yytext));\n",
    "{DIG}+\".\"{DIG}* printf(\"Float: %s (%g)\\n\", yytext, atof(yytext));\n",
    "if|then|begin|end printf(\"Keyword: %s\\n\",yytext);\n",
    "{ID} printf(\"Identifier: %s\\n\",yytext);\n",
    "\"+\"|\"-\"|\"*\"|\"/\"|\">\" printf(\"Operator: %s\\n\",yytext);\n",
    "\"{\"[^}\\n]*\"}\" /* skip one-line comments */\n",
    "[ \\t\\n]+ /* skip whitespace */\n",
    ". printf(\"Unrecognized: %s\\n\",yytext);\n",
    "%%\n",
    "int main(){yylex();} \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "flex -oexample_lex.c example.l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfree( (char *) ptr );\t/* see yyrealloc() for (char *) cast */\n",
      "}\n",
      "\n",
      "#define YYTABLES_NAME \"yytables\"\n",
      "\n",
      "#line 15 \"example.l\"\n",
      "\n",
      "\n",
      "int main(){yylex();}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tail example_lex.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17    63   537 example.l\n",
      " 1804  6479 46378 example_lex.c\n",
      " 1821  6542 46915 total\n"
     ]
    }
   ],
   "source": [
    "wc example.l example_lex.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gcc -oexample_lex example_lex.c -lfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: begin\n",
      "Keyword: if\n",
      "Identifier: size\n",
      "Operator: >\n",
      "Integer: 10 (10)\n",
      "Keyword: then\n",
      "Identifier: size\n",
      "Operator: *\n",
      "Operator: -\n",
      "Float: 3.1415 (3.1415)\n",
      "Keyword: end\n"
     ]
    }
   ],
   "source": [
    "./example_lex < pascal_example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      " if size > 10\n",
      "\tthen size * -3.1415\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "cat pascal_example"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
